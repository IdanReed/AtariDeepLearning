{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0221f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91df5af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import seed_random_generators\n",
    "seed_random_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e551eea",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m      5\u001b[39m holdout_game_dirs = [\n\u001b[32m      6\u001b[39m     dataset_root.joinpath(\u001b[33m\"\u001b[39m\u001b[33mBeamRiderNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBeamRiderNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m      7\u001b[39m     dataset_root.joinpath(\u001b[33m\"\u001b[39m\u001b[33mBreakoutNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBreakoutNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m ]\n\u001b[32m     10\u001b[39m main_game_dirs = [\n\u001b[32m     11\u001b[39m     dataset_root.joinpath(\u001b[33m\"\u001b[39m\u001b[33mEnduroNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mEnduroNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     12\u001b[39m     dataset_root.joinpath(\u001b[33m\"\u001b[39m\u001b[33mMsPacmanNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mMsPacmanNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m     16\u001b[39m     dataset_root.joinpath(\u001b[33m\"\u001b[39m\u001b[33mSpaceInvadersNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSpaceInvadersNoFrameskip-v4\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m episodes = \u001b[43mload_episodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_game_dirs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mholdout_game_dirs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\npz_loader.py:158\u001b[39m, in \u001b[36mload_episodes\u001b[39m\u001b[34m(main_game_dirs, holdout_game_dirs, is_collab)\u001b[39m\n\u001b[32m    155\u001b[39m     dataset_root = \u001b[33m\"\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m sequences_by_game = _fix_obs_paths(game_to_sequences, dataset_root=dataset_root, is_collab=is_collab)\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m episodes = \u001b[43m_build_episodes_from_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequences_by_game\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# Add game ids to episode\u001b[39;00m\n\u001b[32m    161\u001b[39m game_names = \u001b[38;5;28msorted\u001b[39m({episode.game_name \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m episodes})\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\npz_loader.py:124\u001b[39m, in \u001b[36m_build_episodes_from_sequences\u001b[39m\u001b[34m(sequences_by_game)\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start, end):\n\u001b[32m    123\u001b[39m     obs_str = seq_dict[\u001b[33m\"\u001b[39m\u001b[33mobs\u001b[39m\u001b[33m\"\u001b[39m][t]\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     obs_path = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobs_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# arrays are shaped (T, 1) for actions\u001b[39;00m\n\u001b[32m    127\u001b[39m     model_selected_action = seq_dict[\u001b[33m\"\u001b[39m\u001b[33mmodel selected actions\u001b[39m\u001b[33m\"\u001b[39m][t][\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\scoop\\apps\\python\\current\\Lib\\pathlib.py:1162\u001b[39m, in \u001b[36mPath.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1159\u001b[39m     msg = (\u001b[33m\"\u001b[39m\u001b[33msupport for supplying keyword arguments to pathlib.PurePath \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1160\u001b[39m            \u001b[33m\"\u001b[39m\u001b[33mis deprecated and scheduled for removal in Python \u001b[39m\u001b[38;5;132;01m{remove}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1161\u001b[39m     warnings._deprecated(\u001b[33m\"\u001b[39m\u001b[33mpathlib.PurePath(**kwargs)\u001b[39m\u001b[33m\"\u001b[39m, msg, remove=(\u001b[32m3\u001b[39m, \u001b[32m14\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\scoop\\apps\\python\\current\\Lib\\pathlib.py:377\u001b[39m, in \u001b[36mPurePath.__init__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    372\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    373\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    374\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33margument should be a str or an os.PathLike \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    375\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mobject where __fspath__ returns a str, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    376\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(path).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m         paths.append(path)\n\u001b[32m    378\u001b[39m \u001b[38;5;28mself\u001b[39m._raw_paths = paths\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from npz_loader import load_episodes\n",
    "\n",
    "dataset_root = Path(\"dataset\")\n",
    "holdout_game_dirs = [\n",
    "    dataset_root.joinpath(\"BeamRiderNoFrameskip-v4\", \"BeamRiderNoFrameskip-v4\"),\n",
    "    dataset_root.joinpath(\"BreakoutNoFrameskip-v4\", \"BreakoutNoFrameskip-v4\")\n",
    "]\n",
    "\n",
    "main_game_dirs = [\n",
    "    dataset_root.joinpath(\"EnduroNoFrameskip-v4\", \"EnduroNoFrameskip-v4\"),\n",
    "    dataset_root.joinpath(\"MsPacmanNoFrameskip-v4\", \"MsPacmanNoFrameskip-v4\"),\n",
    "    dataset_root.joinpath(\"PongNoFrameskip-v4\", \"PongNoFrameskip-v4\"),\n",
    "    dataset_root.joinpath(\"QbertNoFrameskip-v4\", \"QbertNoFrameskip-v4\"),\n",
    "    dataset_root.joinpath(\"SeaquestNoFrameskip-v4\", \"SeaquestNoFrameskip-v4\"),\n",
    "    dataset_root.joinpath(\"SpaceInvadersNoFrameskip-v4\", \"SpaceInvadersNoFrameskip-v4\")\n",
    "]\n",
    "episodes = load_episodes(main_game_dirs, holdout_game_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523cdbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 1880 items (100.0% of 1880 total)\n"
     ]
    }
   ],
   "source": [
    "from utils import sample_list\n",
    "sampled_episodes = sample_list(episodes, fraction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae8e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from epsiode_dataloader import make_train_val_dataloaders\n",
    "\n",
    "main_bundle, holdout_bundle, bins = make_train_val_dataloaders(\n",
    "    episodes=sampled_episodes,\n",
    "    holdout_game_dirs=holdout_game_dirs,\n",
    "    train_frac=0.8,\n",
    "\n",
    "    # We should experiment with this, but it throws off steps being equal in terms of tokens/timesteps seen\n",
    "    # So I think we keep it as some fixed number for all experiments except for an experiment specifically looking at it\n",
    "    timestep_window_size=4, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fc9d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfedb9",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d499c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kenny started this, might just steal those\n",
    "# Some experiments like freeze below should just use the best params from baseline since there's no changes to the original model,\n",
    "# but other experiments should find their own best params if there are changes to the model (like patch vs CNN)\n",
    "best_baseline_params = {\n",
    "    'lr': 0.002226768831180977,\n",
    "    'emb_size': 128,\n",
    "    'n_layers': 2,\n",
    "    'n_heads': 2,\n",
    "    'num_epochs': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c123937",
   "metadata": {},
   "source": [
    "# Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc3f08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared 0 files from output\\freeze_transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 41734/41734 [20:56<00:00, 33.22it/s]   \n",
      "Epoch 2/2: 100%|██████████| 41734/41734 [19:58<00:00, 34.82it/s]   \n",
      "Finetune 1/2: 100%|██████████| 4249/4249 [03:54<00:00, 18.13it/s] \n",
      "Finetune 2/2: 100%|██████████| 4249/4249 [02:26<00:00, 29.02it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and stats saved to output\\freeze_transformer\\model_checkpoint.pt\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_main_losses_per_head.png\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_main_losses_combined.png\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_main_losses_ema_per_head.png\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_main_losses_ema_combined.png\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_holdout_losses_per_head.png\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_holdout_losses_combined.png\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_holdout_losses_ema_per_head.png\n",
      "Saved plot to output\\freeze_transformer\\model_freeze_transformer_-_holdout_losses_ema_combined.png\n",
      "Saved plot to output\\freeze_transformer\\comparison_freeze_transformer_-_comparison_main_vs_holdout.png\n",
      "Saved plot to output\\freeze_transformer\\comparison_freeze_transformer_-_comparison_per_head_loss.png\n",
      "Saved plot to output\\freeze_transformer\\comparison_freeze_transformer_-_comparison_accuracy.png\n",
      "\n",
      "============================================================\n",
      "HOLDOUT ADAPTATION SUMMARY\n",
      "============================================================\n",
      "Main training steps: 83468\n",
      "Holdout fine-tune steps: 8498\n",
      "\n",
      "Main training - Final loss (EMA): 1.9980\n",
      "Holdout fine-tune - Initial loss (EMA): 4.7755\n",
      "Holdout fine-tune - Final loss (EMA): 1.4237\n",
      "Holdout loss reduction: 3.3517\n",
      "\n",
      "Holdout reached main's final loss at step 187 (2.2% of fine-tuning)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from experiment_freeze import run_experiment_freeze\n",
    "from mgdt_model import Freezeable\n",
    "\n",
    "freeze_params = run_experiment_freeze(\n",
    "    title_prefix=\"Freeze Transformer\",\n",
    "    main_bundle=main_bundle,\n",
    "    holdout_bundle=holdout_bundle,\n",
    "    bins=bins,\n",
    "    freeze_components=[Freezeable.Transformer],\n",
    "    experiment_dir=base_dir.joinpath(\"freeze_transformer\"),\n",
    "    best_params=best_baseline_params,\n",
    ")  # switch to take best params from baseline later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c79033b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared 12 files from output\\freeze_obs_encoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 41734/41734 [21:09<00:00, 32.86it/s]   \n",
      "Epoch 2/2: 100%|██████████| 41734/41734 [19:58<00:00, 34.82it/s]   \n",
      "Finetune 1/2: 100%|██████████| 4249/4249 [02:45<00:00, 25.73it/s]\n",
      "Finetune 2/2: 100%|██████████| 4249/4249 [02:27<00:00, 28.76it/s]\n",
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and stats saved to output\\freeze_obs_encoder\\model_checkpoint.pt\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_main_losses_per_head.png\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_main_losses_combined.png\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_main_losses_ema_per_head.png\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_main_losses_ema_combined.png\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_holdout_losses_per_head.png\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_holdout_losses_combined.png\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_holdout_losses_ema_per_head.png\n",
      "Saved plot to output\\freeze_obs_encoder\\model_freeze_obs_encoder_-_holdout_losses_ema_combined.png\n",
      "Saved plot to output\\freeze_obs_encoder\\comparison_freeze_obs_encoder_-_comparison_main_vs_holdout.png\n",
      "Saved plot to output\\freeze_obs_encoder\\comparison_freeze_obs_encoder_-_comparison_per_head_loss.png\n",
      "Saved plot to output\\freeze_obs_encoder\\comparison_freeze_obs_encoder_-_comparison_accuracy.png\n",
      "\n",
      "============================================================\n",
      "HOLDOUT ADAPTATION SUMMARY\n",
      "============================================================\n",
      "Main training steps: 83468\n",
      "Holdout fine-tune steps: 8498\n",
      "\n",
      "Main training - Final loss (EMA): 2.0379\n",
      "Holdout fine-tune - Initial loss (EMA): 4.6168\n",
      "Holdout fine-tune - Final loss (EMA): 1.4828\n",
      "Holdout loss reduction: 3.1340\n",
      "\n",
      "Holdout reached main's final loss at step 110 (1.3% of fine-tuning)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "_ = run_experiment_freeze(\n",
    "    title_prefix=\"Freeze Obs Encoder\",\n",
    "    main_bundle=main_bundle,\n",
    "    holdout_bundle=holdout_bundle,\n",
    "    bins=bins,\n",
    "    freeze_components=[Freezeable.ObsEncoder],\n",
    "    experiment_dir=base_dir.joinpath(\"freeze_obs_encoder\"),\n",
    "    best_params=freeze_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b21c672",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31fe0b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-09 10:16:01,778] A new study created in memory with name: no-name-a11a1905-54d3-41f9-b3fd-65eda4e2bf87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params: {'lr': 7.312775732692473e-05, 'emb_size': 64, 'n_layers': 3, 'n_heads': 4, 'num_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 41734/41734 [14:44<00:00, 47.17it/s]\n",
      "Epoch 2/3: 100%|██████████| 41734/41734 [14:57<00:00, 46.52it/s]\n",
      "Epoch 3/3: 100%|██████████| 41734/41734 [14:45<00:00, 47.11it/s]\n",
      "[I 2025-12-09 11:13:10,174] Trial 0 finished with value: 1.5751007795333862 and parameters: {'lr': 7.312775732692473e-05, 'emb_size': 64, 'n_layers': 3, 'n_heads': 4, 'num_epochs': 3}. Best is trial 0 with value: 1.5751007795333862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params: {'lr': 3.088368723207604e-05, 'emb_size': 64, 'n_layers': 6, 'n_heads': 4, 'num_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 41734/41734 [18:56<00:00, 36.71it/s]\n",
      "Epoch 2/3: 100%|██████████| 41734/41734 [18:57<00:00, 36.67it/s]\n",
      "Epoch 3/3: 100%|██████████| 41734/41734 [19:05<00:00, 36.45it/s]\n",
      "[I 2025-12-09 12:23:06,355] Trial 1 finished with value: 1.7595354318618774 and parameters: {'lr': 3.088368723207604e-05, 'emb_size': 64, 'n_layers': 6, 'n_heads': 4, 'num_epochs': 3}. Best is trial 0 with value: 1.5751007795333862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params: {'lr': 0.006743403888083983, 'emb_size': 512, 'n_layers': 5, 'n_heads': 1, 'num_epochs': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 41734/41734 [24:44<00:00, 28.11it/s]  \n",
      "Epoch 2/5: 100%|██████████| 41734/41734 [16:19<00:00, 42.59it/s]\n",
      "Epoch 3/5: 100%|██████████| 41734/41734 [16:36<00:00, 41.87it/s]\n",
      "Epoch 4/5: 100%|██████████| 41734/41734 [16:21<00:00, 42.53it/s]\n",
      "Epoch 5/5: 100%|██████████| 41734/41734 [16:35<00:00, 41.90it/s]\n",
      "[I 2025-12-09 14:17:41,939] Trial 2 finished with value: 7335.21240234375 and parameters: {'lr': 0.006743403888083983, 'emb_size': 512, 'n_layers': 5, 'n_heads': 1, 'num_epochs': 5}. Best is trial 0 with value: 1.5751007795333862.\n",
      "[I 2025-12-09 14:17:41,940] Trial 3 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params: {'lr': 0.0004072739983235087, 'emb_size': 256, 'n_layers': 5, 'n_heads': 3, 'num_epochs': 4}\n",
      "Trial params: {'lr': 3.821873872825288e-05, 'emb_size': 128, 'n_layers': 5, 'n_heads': 4, 'num_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 41734/41734 [17:11<00:00, 40.46it/s]\n",
      "[I 2025-12-09 14:39:09,531] Trial 4 finished with value: 1.8784879446029663 and parameters: {'lr': 3.821873872825288e-05, 'emb_size': 128, 'n_layers': 5, 'n_heads': 4, 'num_epochs': 1}. Best is trial 0 with value: 1.5751007795333862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params: {'lr': 0.007190890680147319, 'emb_size': 64, 'n_layers': 5, 'n_heads': 1, 'num_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 41734/41734 [16:42<00:00, 41.65it/s]\n",
      "[I 2025-12-09 15:00:06,369] Trial 5 finished with value: 1.7167880535125732 and parameters: {'lr': 0.007190890680147319, 'emb_size': 64, 'n_layers': 5, 'n_heads': 1, 'num_epochs': 1}. Best is trial 0 with value: 1.5751007795333862.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params: {'lr': 0.0014038110531100418, 'emb_size': 256, 'n_layers': 4, 'n_heads': 4, 'num_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 41734/41734 [15:17<00:00, 45.51it/s]\n",
      "Epoch 2/4: 100%|██████████| 41734/41734 [15:22<00:00, 45.22it/s]\n",
      "Epoch 3/4: 100%|██████████| 41734/41734 [15:17<00:00, 45.49it/s]\n",
      "Epoch 4/4: 100%|██████████| 41734/41734 [15:16<00:00, 45.54it/s]\n",
      "[I 2025-12-09 16:18:27,868] Trial 6 finished with value: 1.341511845588684 and parameters: {'lr': 0.0014038110531100418, 'emb_size': 256, 'n_layers': 4, 'n_heads': 4, 'num_epochs': 4}. Best is trial 6 with value: 1.341511845588684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial params: {'lr': 0.0034597371545648167, 'emb_size': 256, 'n_layers': 6, 'n_heads': 2, 'num_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 41734/41734 [18:47<00:00, 37.01it/s]\n",
      "Epoch 2/2:  29%|██▉       | 12160/41734 [04:51<11:49, 41.68it/s]\n",
      "[W 2025-12-09 16:47:16,125] Trial 7 failed with parameters: {'lr': 0.0034597371545648167, 'emb_size': 256, 'n_layers': 6, 'n_heads': 2, 'num_epochs': 2} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 205, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\optuna_tuning.py\", line 33, in objective\n",
      "    model, main_train_stats, main_val_stats = train_mgdt(\n",
      "                                              ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\mgdt_model_trainer.py\", line 163, in train_mgdt\n",
      "    total_grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0).item()\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 43, in _no_grad_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 231, in clip_grad_norm_\n",
      "    total_norm = _get_total_norm(grads, norm_type, error_if_nonfinite, foreach)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 43, in _no_grad_wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\", line 96, in _get_total_norm\n",
      "    norms.extend(torch._foreach_norm(device_tensors, norm_type))\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-09 16:47:16,145] Trial 7 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexperiment_basic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_experiment_basic\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmgdt_model_trainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Encoder\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m _ = \u001b[43mrun_experiment_basic\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCNN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmain_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mholdout_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoinpath\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcnn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEncoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCNN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\experiment_basic.py:23\u001b[39m, in \u001b[36mrun_experiment_basic\u001b[39m\u001b[34m(title_prefix, main_bundle, holdout_bundle, bins, experiment_dir, encoder_type, best_params)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptuna_tuning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_optuna\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     study = \u001b[43mrun_optuna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_bundle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmain_bundle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     best_params = study.best_params\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Train with best params\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\optuna_tuning.py:48\u001b[39m, in \u001b[36mrun_optuna\u001b[39m\u001b[34m(train_loader, val_loader, bins, n_trials, lr_range, emb_size_choices, n_layers_range, n_heads_range, num_epochs_range, encoder_type)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m main_val_stats[-\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     47\u001b[39m study = optuna.create_study(direction=\u001b[33m'\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\optuna\\study\\_optimize.py:67\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     80\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\optuna\\study\\_optimize.py:164\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     frozen_trial_id = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\optuna\\study\\_optimize.py:262\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    255\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    258\u001b[39m     updated_state == TrialState.FAIL\n\u001b[32m    259\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    261\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m trial._trial_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\optuna\\study\\_optimize.py:205\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    207\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    208\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\optuna_tuning.py:33\u001b[39m, in \u001b[36mrun_optuna.<locals>.objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m emb_size % n_heads != \u001b[32m0\u001b[39m:\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m optuna.exceptions.TrialPruned()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m model, main_train_stats, main_val_stats = \u001b[43mtrain_mgdt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataloader_val\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43memb_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43memb_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_every_pct\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Only validate at epoch end during tuning for speed\u001b[39;49;00m\n\u001b[32m     44\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m main_val_stats[-\u001b[32m1\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\mgdt_model_trainer.py:163\u001b[39m, in \u001b[36mtrain_mgdt\u001b[39m\u001b[34m(bins, dataloader_train, dataloader_val, model, num_epochs, val_every_pct, mid_epoch_val_fraction, val_seed, encoder_type, image_size, emb_size, n_layers, n_heads, max_timestep_window_size, lr, finetune_lr_factor, weight_decay, device)\u001b[39m\n\u001b[32m    160\u001b[39m scaler.unscale_(optimizer)\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Clip grad and get norm (clip_grad_norm_ returns the norm)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m total_grad_norm = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m.item()\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Optimizer step with scaler\u001b[39;00m\n\u001b[32m    166\u001b[39m scaler.step(optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:231\u001b[39m, in \u001b[36mclip_grad_norm_\u001b[39m\u001b[34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m    226\u001b[39m         warnings.warn(\n\u001b[32m    227\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`parameters` is an empty generator, no gradient clipping will occur.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    228\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m    229\u001b[39m         )\n\u001b[32m    230\u001b[39m grads = [p.grad \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters \u001b[38;5;28;01mif\u001b[39;00m p.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m total_norm = \u001b[43m_get_total_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_if_nonfinite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    232\u001b[39m _clip_grads_with_norm_(parameters, max_norm, total_norm, foreach)\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_norm\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:43\u001b[39m, in \u001b[36m_no_grad.<locals>._no_grad_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_no_grad_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\idanc\\local\\projects\\AtariDeepLearning\\.venv_atari\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:96\u001b[39m, in \u001b[36m_get_total_norm\u001b[39m\u001b[34m(tensors, norm_type, error_if_nonfinite, foreach)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (device, _), ([device_tensors], _) \u001b[38;5;129;01min\u001b[39;00m grouped_tensors.items():\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (foreach \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _has_foreach_support(device_tensors, device)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m     94\u001b[39m         foreach \u001b[38;5;129;01mand\u001b[39;00m _device_has_foreach_support(device)\n\u001b[32m     95\u001b[39m     ):\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         norms.extend(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_foreach_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m foreach:\n\u001b[32m     98\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     99\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mforeach=True was passed, but can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt use the foreach API on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice.type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from experiment_basic import run_experiment_basic\n",
    "from mgdt_model_trainer import Encoder\n",
    "\n",
    "_ = run_experiment_basic(\n",
    "    \"CNN\",\n",
    "    main_bundle,\n",
    "    holdout_bundle,\n",
    "    bins,\n",
    "    base_dir.joinpath(\"cnn\"),\n",
    "    encoder_type=Encoder.CNN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd4b21",
   "metadata": {},
   "source": [
    "# Window Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac020836",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bundle_window_8, holdout_bundle_window_8, bins_window_8 = make_train_val_dataloaders(\n",
    "    episodes=sampled_episodes,\n",
    "    holdout_game_dirs=holdout_game_dirs,\n",
    "    train_frac=0.8,\n",
    "    timestep_window_size=8, \n",
    ")\n",
    "_ = run_experiment_basic(\n",
    "    \"Window Size 8\",\n",
    "    main_bundle_window_8,\n",
    "    holdout_bundle_window_8,\n",
    "    bins_window_8,\n",
    "    base_dir.joinpath(\"window_size_8\"),\n",
    "    encoder_type=Encoder.Patch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e68ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bundle_window_16, holdout_bundle_window_16, bins_window_16 = make_train_val_dataloaders(\n",
    "    episodes=sampled_episodes,\n",
    "    holdout_game_dirs=holdout_game_dirs,\n",
    "    train_frac=0.8,\n",
    "    timestep_window_size=16, \n",
    ")\n",
    "_ = run_experiment_basic(\n",
    "    \"Window Size 16\",\n",
    "    main_bundle_window_16,\n",
    "    holdout_bundle_window_16,\n",
    "    bins_window_16,\n",
    "    base_dir.joinpath(\"window_size_16\"),\n",
    "    encoder_type=Encoder.Patch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_bundle_window_32, holdout_bundle_window_32, bins_window_32 = make_train_val_dataloaders(\n",
    "    episodes=sampled_episodes,\n",
    "    holdout_game_dirs=holdout_game_dirs,\n",
    "    train_frac=0.8,\n",
    "    timestep_window_size=32, \n",
    ")\n",
    "_ = run_experiment_basic(\n",
    "    \"Window Size 32\",\n",
    "    main_bundle_window_32,\n",
    "    holdout_bundle_window_32,\n",
    "    bins_window_32,\n",
    "    base_dir.joinpath(\"window_size_32\"),\n",
    "    encoder_type=Encoder.Patch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64871c9d",
   "metadata": {},
   "source": [
    "# Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as baseline, but just in case something goes wrong with kenny's run\n",
    "# Set to run last in case this takes >1 day\n",
    "from experiment_basic import run_experiment_basic\n",
    "from mgdt_model_trainer import Encoder\n",
    "\n",
    "# _ = run_experiment_basic(\n",
    "#     \"Patch\",\n",
    "#     main_bundle,\n",
    "#     holdout_bundle,\n",
    "#     bins,\n",
    "#     base_dir.joinpath(\"patch\"),\n",
    "#     encoder_type=Encoder.Patch,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a88be7",
   "metadata": {},
   "source": [
    "# Comparison \n",
    "## *Keep this at bottom of notebook and add new experiments to it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6850c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_checkpoint\n",
    "from mgdt_model_stats import ExperimentData\n",
    "from pathlib import Path\n",
    "\n",
    "base_dir = Path(\"output\")\n",
    "\n",
    "def load_experiment_data(name: str, output_dir: Path) -> ExperimentData:\n",
    "    checkpoint = load_checkpoint(output_dir)\n",
    "    return ExperimentData(\n",
    "        name=name,\n",
    "        main_train_stats=checkpoint.main_train_stats,\n",
    "        main_val_stats=checkpoint.main_val_stats,\n",
    "        holdout_train_stats=checkpoint.holdout_train_stats,\n",
    "        holdout_val_stats=checkpoint.holdout_val_stats,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8713ae6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from output\\freeze_transformer\\model_checkpoint.pt\n",
      "Loaded checkpoint from output\\freeze_obs_encoder\\model_checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "test_data_1 = load_experiment_data(\"Freeze Transformer\", base_dir.joinpath(\"freeze_transformer\"))\n",
    "test_data_2 = load_experiment_data(\"Freeze Obs Encoder\", base_dir.joinpath(\"freeze_obs_encoder\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc399a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: Freeze Transformer\n",
      "----------------------------------------\n",
      "  Holdout train F1: ✗\n",
      "  Holdout val F1:   ✓\n",
      "    F1 range: 0.1146 - 1.0000\n",
      "\n",
      "Experiment: Freeze Obs Encoder\n",
      "----------------------------------------\n",
      "  Holdout train F1: ✗\n",
      "  Holdout val F1:   ✓\n",
      "    F1 range: 0.1393 - 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: verify F1 data is present\n",
    "def check_f1_data(data: ExperimentData):\n",
    "    print(f\"Experiment: {data.name}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Check training stats\n",
    "    if data.holdout_train_stats:\n",
    "        has_train_f1 = \"action_f1\" in data.holdout_train_stats[0]\n",
    "        print(f\"  Holdout train F1: {'✓' if has_train_f1 else '✗'}\")\n",
    "    else:\n",
    "        print(f\"  Holdout train stats: empty\")\n",
    "    \n",
    "    # Check validation stats\n",
    "    if data.holdout_val_stats:\n",
    "        has_val_f1 = \"action_f1\" in data.holdout_val_stats[0]\n",
    "        print(f\"  Holdout val F1:   {'✓' if has_val_f1 else '✗'}\")\n",
    "        if has_val_f1:\n",
    "            f1_values = [s.get(\"action_f1\") for s in data.holdout_val_stats]\n",
    "            print(f\"    F1 range: {min(f1_values):.4f} - {max(f1_values):.4f}\")\n",
    "    else:\n",
    "        print(f\"  Holdout val stats: empty\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "check_f1_data(test_data_1)\n",
    "check_f1_data(test_data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b9e9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from output\\freeze_transformer\\model_checkpoint.pt\n",
      "Loaded checkpoint from output\\freeze_obs_encoder\\model_checkpoint.pt\n",
      "Saved plot to output\\experiment_comparison\\experiment_comparison_holdout_val_loss.png\n",
      "Saved plot to output\\experiment_comparison\\experiment_comparison_holdout_val_f1.png\n",
      "Saved plot to output\\experiment_comparison\\experiment_comparison_holdout_val_acc.png\n",
      "Saved plot to output\\experiment_comparison\\experiment_comparison_holdout_train_acc.png\n",
      "Saved plot to output\\experiment_comparison\\experiment_comparison_steps_to_acc.png\n",
      "Saved plot to output\\experiment_comparison\\experiment_comparison_steps_to_f1.png\n",
      "\n",
      "======================================================================\n",
      "EXPERIMENT COMPARISON SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Freeze Transformer:\n",
      "----------------------------------------\n",
      "  Total holdout training steps: 8498\n",
      "  Final holdout val loss: 1.4502\n",
      "  Final holdout val F1: 0.3939\n",
      "  Final holdout val accuracy: 0.6408\n",
      "  Steps to reach F1 thresholds (validation):\n",
      "    F1 >= 0.3: 849 steps\n",
      "    F1 >= 0.4: 849 steps\n",
      "    F1 >= 0.5: not reached\n",
      "    F1 >= 0.6: not reached\n",
      "  Steps to reach accuracy thresholds:\n",
      "    Acc >= 0.3: 1 steps\n",
      "    Acc >= 0.4: 4 steps\n",
      "    Acc >= 0.5: 4 steps\n",
      "    Acc >= 0.6: 34 steps\n",
      "    Acc >= 0.7: 34 steps\n",
      "\n",
      "Freeze Obs Encoder:\n",
      "----------------------------------------\n",
      "  Total holdout training steps: 8498\n",
      "  Final holdout val loss: 1.3887\n",
      "  Final holdout val F1: 0.4205\n",
      "  Final holdout val accuracy: 0.6542\n",
      "  Steps to reach F1 thresholds (validation):\n",
      "    F1 >= 0.3: 849 steps\n",
      "    F1 >= 0.4: 849 steps\n",
      "    F1 >= 0.5: 8494 steps\n",
      "    F1 >= 0.6: not reached\n",
      "  Steps to reach accuracy thresholds:\n",
      "    Acc >= 0.3: 2 steps\n",
      "    Acc >= 0.4: 2 steps\n",
      "    Acc >= 0.5: 7 steps\n",
      "    Acc >= 0.6: 28 steps\n",
      "    Acc >= 0.7: 43 steps\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'steps_to_f1_threshold': {'Freeze Transformer': {0.3: 849,\n",
       "   0.4: 849,\n",
       "   0.5: None,\n",
       "   0.6: None},\n",
       "  'Freeze Obs Encoder': {0.3: 849, 0.4: 849, 0.5: 8494, 0.6: None}},\n",
       " 'steps_to_acc_threshold': {'Freeze Transformer': {0.3: 1,\n",
       "   0.4: 4,\n",
       "   0.5: 4,\n",
       "   0.6: 34,\n",
       "   0.7: 34},\n",
       "  'Freeze Obs Encoder': {0.3: 2, 0.4: 2, 0.5: 7, 0.6: 28, 0.7: 43}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mgdt_model_stats import experiment_comparison\n",
    "\n",
    "experiments = [\n",
    "    load_experiment_data(\"Freeze Transformer\", base_dir.joinpath(\"freeze_transformer\")),\n",
    "    load_experiment_data(\"Freeze Obs Encoder\", base_dir.joinpath(\"freeze_obs_encoder\")),\n",
    "    # load_experiment_data(\"CNN\", base_dir.joinpath(\"cnn\")),\n",
    "    # load_experiment_data(\"Window Size 8\", base_dir.joinpath(\"window_size_8\")),\n",
    "    # load_experiment_data(\"Window Size 16\", base_dir.joinpath(\"window_size_16\")),\n",
    "    # load_experiment_data(\"Window Size 32\", base_dir.joinpath(\"window_size_32\")),\n",
    "    # load_experiment_data(\"Patch\", base_dir.joinpath(\"patch\")),\n",
    "]\n",
    "\n",
    "experiment_comparison(experiments, output_dir=base_dir.joinpath(\"experiment_comparison\"), no_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f2917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_atari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
